{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d529df1-5863-479f-aa1b-c32c8cb1dae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "max_seq_length=2048\n",
    "dtype = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726632b-b052-414e-ab44-b671e67b6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yourmodeldir\"  # 你的本地模型路径\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a356586-6682-40dc-bae0-8a502eee6495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载本地微调后的模型\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    # load_in_4bit=True\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "print(f\"模型参数量: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf71045-1bb4-442f-9708-1a72c58394a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这里不使用环境变量，直接填入wandb的token,如果没有token可以去官网下载一个\n",
    "import wandb\n",
    "\n",
    "wandb.login(key=\"yourkey\")\n",
    "run = wandb.init(\n",
    "    project='ingratiation dsr18b',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21f464-03a9-4184-b7ef-7605b84a2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修复JSON格式，确保'课程名称'和'分类'前面有逗号\n",
    "def fix_json_commas(json_string):\n",
    "    json_string = re.sub(r'([^,{])(\\\"课程名称\\\")', r'\\1,\\2', json_string)  # 只有当前面不是 `,` 或 `{` 时补逗号\n",
    "    json_string = re.sub(r'([^,{])(\\\"分类\\\")', r'\\1,\\2', json_string)  # 只有当前面不是 `,` 或 `{` 时补逗号\n",
    "    json_string = re.sub(r',\\s*}', '}', json_string)\n",
    "    return json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a38c5-3307-4bd2-9257-878ac97b0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单次响应函数\n",
    "@torch.no_grad()\n",
    "def get_response(input_message):\n",
    "    inputs = tokenizer(input_message, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.8,\n",
    "        repetition_penalty=1.2,\n",
    "        use_cache=True,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response_text = response_text.split(\"</think>\")[-1].strip()\n",
    "    cleaned_res = response_text.replace(input_message, '').strip().replace('```json', '').replace('```', '').replace(' ', '').replace('\\n', '').replace('\\\\\"', '\"')\n",
    "    cleaned_res = re.sub(\"'\", '\"', cleaned_res)\n",
    "    cleaned_res = re.sub(r':\"\"(.*?)\"\"', r':\"\\1\"', cleaned_res)\n",
    "    cleaned_res = fix_json_commas(cleaned_res)\n",
    "    answer = response_text.split(\"</think>\")[-1].strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5db409-98a7-4b16-a4a2-ec438e57ac75",
   "metadata": {},
   "source": [
    "## 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afe2e3-2ce2-47ee-b312-7a7d5b9d614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"你是教育学专家，正在对学习者在线课堂中的弹幕进行行为分类。\n",
    "[分类规则]={{\n",
    "    \"观点遵从\"：明确或间接地附和教师观点，表达对教师论点或行为的一致认同。\n",
    "    \"恭维他人\"：直接或间接赞美教师、强调教师的重要性与优点。\n",
    "    \"自我展现\"：突出自己的见解、经验或成就，以期引起教师注意。\n",
    "    \"施恩他人\"：表达对教师或同学的帮助意愿，用行动或建议来支持他人。\n",
    "}}\n",
    "### 指令:\n",
    "你需要对每个弹幕内容进行判断，课程名称包含场景信息，回答仅输出JSON，不在4类分类中请输出\"无\"\n",
    "[输出格式]=\n",
    "{{\n",
    "    \"分类\": str分类\n",
    "}}\n",
    "### 问题:\n",
    "{}请仅输出[输出格式]内容，不要生成多余信息\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd0aeb-d0b1-41d1-bc32-1051c7c085c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"{'弹幕内容': '是', '课程名称': '数据结构'}属于什么分类？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ccd80-eba1-45fa-98ab-409ace8f14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_response(prompt_style.format(question))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807a3df-6f21-481d-af68-d2df45a3a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    从文本中提取符合 {\"弹幕内容\": \"XXX\", \"课程名称\": \"XXX\", \"分类\": \"XXX\"} 结构的 JSON 数据\n",
    "    \"\"\"\n",
    "    json_pattern = r'(\\{.*?\"分类\".*?\\})'\n",
    "    matches = re.findall(json_pattern, text, re.DOTALL)\n",
    "    \n",
    "    for match in matches:\n",
    "        try:\n",
    "            parsed_json = json.loads(match)  # 解析 JSON\n",
    "            return parsed_json  # 返回找到的 JSON 数据\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # 解析失败，尝试下一个匹配项\n",
    "    \n",
    "    return None  # 没有找到有效 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab344b6-b199-4d4f-a61b-00803bec3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化后的批量推理函数\n",
    "@torch.no_grad()\n",
    "def get_response_batch(questions):\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.8,\n",
    "        repetition_penalty=1.2,\n",
    "        use_cache=True,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    responses = []\n",
    "    for question, response_text in zip(questions, decoded_outputs):\n",
    "        try:\n",
    "            response_text = response_text.split(\"</think>\")[-1].strip()\n",
    "            # print(response_text)\n",
    "            cleaned_res = response_text.replace(question, '').strip().replace('```json', '').replace('```', '').replace(' ', '').replace('\\n', '').replace('\\\\\"', '\"')\n",
    "            cleaned_res = re.sub(\"'\", '\"', cleaned_res)\n",
    "            cleaned_res = re.sub(r':\"\"(.*?)\"\"', r':\"\\1\"', cleaned_res)\n",
    "            cleaned_res = fix_json_commas(cleaned_res)\n",
    "            print(f\"cleaned_res={cleaned_res}\")\n",
    "            parsed = json.loads(cleaned_res)\n",
    "            if isinstance(parsed, list):\n",
    "                parsed = parsed[0] if parsed else {}\n",
    "            responses.append(parsed)\n",
    "        except json.JSONDecodeError:\n",
    "            # **解析失败，尝试从文本中提取 JSON**\n",
    "            extracted_json = extract_json_from_text(cleaned_res)\n",
    "            if extracted_json:\n",
    "                parsed = extracted_json  # 使用提取的 JSON\n",
    "                responses.append(parsed)\n",
    "            else:\n",
    "                eee = {\"error\": \"无法解析 JSON，且未找到有效 JSON 结构\"}\n",
    "                print(eee)\n",
    "                # print(f\"outputs={decoded_outputs}\")\n",
    "                \n",
    "                responses.append({\"error\": str(eee)})\n",
    "                # print(\"本轮结束\")\n",
    "                # break\n",
    "        except Exception as e:\n",
    "            responses.append({\"error\": str(e)})\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa831ec8-ae40-4e5c-b9a8-33122ddaec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载train test数据\n",
    "with open('Ingratiation/train_data0320.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('Ingratiation/test_data0320.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d3a2d-fa09-449a-9309-4c16d7d2cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, data_type=\"train\", BATCH_SIZE=8):\n",
    "    \"\"\"\n",
    "    批量处理函数\n",
    "    :param data: 需要处理的数据（列表，每个元素为包含 \"Question\" 和 \"Response\" 的字典）\n",
    "    :param data_type: 字符串，用于区分 'train' 或 'test'，将影响输出文件命名\n",
    "    :param BATCH_SIZE: 每次批量处理的数据条数\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    error_logs = []\n",
    "\n",
    "    # 按 BATCH_SIZE 处理数据\n",
    "    for i in range(0, len(data), BATCH_SIZE):\n",
    "        # 打印处理进度\n",
    "        if i % 256 == 0:\n",
    "            print(f\"第{i}个正在处理，当前类型：{data_type}\")\n",
    "        batch_data = data[i : i + BATCH_SIZE]\n",
    "        questions_batch = [prompt_style.format(item[\"Question\"]) for item in batch_data]\n",
    "\n",
    "        # 批量请求接口\n",
    "        batch_responses = get_response_batch(questions_batch)\n",
    "        # print(f\"第{i}个输出：{batch_responses}\")\n",
    "        for j, response_data in enumerate(batch_responses):\n",
    "            original_response = batch_data[j][\"Response\"]\n",
    "            original_response_gt = original_response[\"分类\"]\n",
    "            # 判断是否返回错误或字段缺失\n",
    "            if (\n",
    "                \"error\" in response_data \n",
    "                or not all(key in response_data for key in [\"分类\"])\n",
    "            ):\n",
    "                # 收集错误信息\n",
    "                error_logs.append({\n",
    "                    \"Question\": batch_data[j][\"Question\"],\n",
    "                    \"原分类\": original_response_gt,\n",
    "                    \"错误信息\": response_data.get(\"error\", \"响应缺少必要字段\")\n",
    "                })\n",
    "                continue  # 跳过失败的条目\n",
    "\n",
    "            # 存储成功的结果\n",
    "            results.append({\n",
    "                \"Question\": batch_data[j][\"Question\"],\n",
    "                \"分类\": response_data[\"分类\"],\n",
    "                \"原分类\": original_response_gt\n",
    "            })\n",
    "\n",
    "    # 获取当前时间戳\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 根据 data_type 区分输出文件的命名\n",
    "    if data_type.lower() == \"train\":\n",
    "        result_file = f\"df_train_{current_time}.xlsx\"\n",
    "        error_file = f\"error_train_log_{current_time}.xlsx\"\n",
    "    elif data_type.lower() == \"after_train\":\n",
    "        result_file = f\"df_after_train_{current_time}.xlsx\"\n",
    "        error_file = f\"error_after_train_log_{current_time}.xlsx\"\n",
    "    elif data_type.lower() == \"after_test\":\n",
    "        result_file = f\"df_after_test_{current_time}.xlsx\"\n",
    "        error_file = f\"error_after_test_log_{current_time}.xlsx\"\n",
    "    else:\n",
    "        # 默认使用 test 命名\n",
    "        result_file = f\"df_test_{current_time}.xlsx\"\n",
    "        error_file = f\"error_test_log_{current_time}.xlsx\"\n",
    "    df_result = pd.DataFrame()\n",
    "    df_error = pd.DataFrame()\n",
    "    # 保存结果\n",
    "    if results:\n",
    "        df_result = pd.DataFrame(results)\n",
    "        df_result.to_excel(result_file, index=False)\n",
    "        print(f\"{data_type} 处理完成，结果已保存至 {result_file}\")\n",
    "    \n",
    "    if error_logs:\n",
    "        df_error = pd.DataFrame(error_logs)\n",
    "        df_error.to_excel(error_file, index=False)\n",
    "        print(f\"{data_type} 处理完成，错误日志已保存至 {error_file}\")\n",
    "    return df_result,df_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81568d-0b35-4611-b3ec-82843dd0c55c",
   "metadata": {},
   "source": [
    "### 训练集模型分类情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01efd3-109a-42de-8287-b40ebd055646",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time1 = datetime.now()\n",
    "df_train_result,df_train_error_result = process_data(train_data, data_type=\"train\", BATCH_SIZE=128)\n",
    "current_time2 = datetime.now()\n",
    "print(f'用时{(current_time2-current_time1).total_seconds()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f742e1-cabe-49a7-8b94-6bbdd388e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train_result))\n",
    "print(len(df_train_error_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b415ea2-14f4-4254-8f99-740bdc00a600",
   "metadata": {},
   "source": [
    "## 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae86984-30b3-4476-b1ba-7e29a9846588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_result,df_test_error_result = process_data(test_data, data_type=\"test\", BATCH_SIZE=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec53d41-237c-446f-a8a7-7c6db2d24024",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_test_result))\n",
    "print(len(df_test_error_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea2ac5-b132-4651-8099-5a2fff996176",
   "metadata": {},
   "source": [
    "## SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459b11d-be42-4903-bd40-9e8b2d02d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"你是教育学专家，正在对学习者在线课堂中的弹幕进行行为分类。\n",
    "[分类规则]={{\n",
    "    \"观点遵从\"：明确或间接地附和教师观点，表达对教师论点或行为的一致认同。\n",
    "    \"恭维他人\"：直接或间接赞美教师、强调教师的重要性与优点。\n",
    "    \"自我展现\"：突出自己的见解、经验或成就，以期引起教师注意。\n",
    "    \"施恩他人\"：表达对教师或同学的帮助意愿，用行动或建议来支持他人。\n",
    "}}\n",
    "### 指令:\n",
    "你需要对每个弹幕内容进行判断，课程名称包含场景信息，回答仅输出JSON格式，不在4类分类中请输出\"无\"\n",
    "[输出格式]=\n",
    "{{\n",
    "    \"分类\": str分类\n",
    "}}\n",
    "### 问题:\n",
    "{}你的回答内容必须是合法 JSON 结构，不可包含多余说明\n",
    "### 思考:\n",
    "{}\n",
    "### 回答：\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25980900-d6fe-4b0f-b1f0-60326c6f3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"Question\"]  # 问题\n",
    "    cots = examples[\"Complex_CoT\"]  # 复杂思考\n",
    "    outputs = examples[\"Response\"]  # 模型最终回答\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        # 生成完整的训练输入文本\n",
    "        full_text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(full_text)\n",
    "\n",
    "        # Tokenize 整个输入\n",
    "        tokenized = tokenizer(full_text, truncation=True, max_length=1024, padding=\"max_length\")\n",
    "\n",
    "        # Tokenize CoT + Response（计算损失部分）\n",
    "        response_text = str(output) + EOS_TOKEN\n",
    "        tokenized__response = tokenizer(response_text, truncation=True, max_length=256, padding=\"max_length\")\n",
    "\n",
    "        # 获取 Question 的 Token 长度\n",
    "        input_len = len(tokenized[\"input_ids\"]) - len(tokenized__response[\"input_ids\"])\n",
    "\n",
    "        # 生成 labels，前面 Question 部分设为 -100（忽略计算损失），CoT + Response 计算损失\n",
    "        label_ids = [-100] * input_len + tokenized__response[\"input_ids\"]\n",
    "        label_ids = label_ids + [-100] * (1024 - len(label_ids))\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "        \"input_ids\": [tokenizer(text, truncation=True, max_length=1024)[\"input_ids\"] for text in texts],\n",
    "        \"attention_mask\": [tokenizer(text, truncation=True, max_length=1024)[\"attention_mask\"] for text in texts],\n",
    "        \"labels\": labels,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0154b7f-49c8-405f-a448-608491123b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"Ingratiation/train_data0320.json\",  # 直接指定文件路径\n",
    "    split=\"train\",\n",
    ")\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# 3) 从 Response 提取分类标签\n",
    "# -------------------------------\n",
    "df[\"label\"] = df[\"Response\"].apply(lambda x: x[\"分类\"])\n",
    "\n",
    "# 4) 使用 sklearn 进行分层切分\n",
    "train_df, eval_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,       # 20% 验证集\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"] # 按 label 分层抽样\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5) 转回 Hugging Face Dataset\n",
    "# -------------------------------\n",
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "eval_dataset = Dataset.from_pandas(eval_df, preserve_index=False)\n",
    "\n",
    "# -------------------------------\n",
    "# 6) 对训练集和验证集执行 map\n",
    "# -------------------------------\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "eval_dataset = eval_dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# eval_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c83db-5482-4e07-aaa5-9336d067301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c1ee4-2866-4116-bd0a-32f4e0c3e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae38a71-1e04-4dc6-95fa-60a9966e259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_training(model)\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\", \n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697155f-a186-4663-b4c6-3cd5924562ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,  # 训练集\n",
    "    eval_dataset=eval_dataset,    # 验证集\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,  # 验证集的批量大小\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=10,\n",
    "        max_steps=300,\n",
    "        learning_rate=5e-5,\n",
    "        optim=\"adamw_hf\",\n",
    "        weight_decay=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        tf32=True,\n",
    "        gradient_checkpointing=True,\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",  # 按步数评估\n",
    "        eval_steps=10,               # 每 20 步评估一次\n",
    "        save_strategy=\"steps\",       # 按步数保存模型\n",
    "        save_steps=10,               # 每 20 步保存一次模型\n",
    "        save_total_limit=2,          # 最多保存 2 个检查点\n",
    "        load_best_model_at_end=True, # 训练结束时加载最佳模型\n",
    "        metric_for_best_model=\"eval_loss\",  # 根据验证集损失选择最佳模型\n",
    "        greater_is_better=False,    # 损失越小越好\n",
    "        seed=42,\n",
    "        output_dir=\"outputs_ingratiation\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4745b4-393d-4652-8e3d-0011406fc98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687eaea-5a37-4d51-b5bb-0b04aadd225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950b7dd-7a0c-4b91-932a-802c2ef1b244",
   "metadata": {},
   "source": [
    "### 本地保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb7d9e-18e4-4eb0-a1b1-af7bb6501e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_local = \"DeepSeek-R1-Ingratiation-COT-0317\"\n",
    "model.save_pretrained(new_model_local) # Local saving\n",
    "tokenizer.save_pretrained(new_model_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87accb69-cea3-4339-9d27-6fd91105aa92",
   "metadata": {},
   "source": [
    "## 运行本地保存的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9bf61-a795-4ca4-b9db-76bf631b505f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"DeepSeek-R1-Ingratiation-COT-0317\"  # 你的本地模型路径\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype = dtype,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bad534-0057-4b40-b1fc-075e911854b2",
   "metadata": {},
   "source": [
    "## 训练后模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3eff7c-b9c8-4947-a19f-593dc1763089",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 批量处理训练集\n",
    "current_time1 = datetime.now()\n",
    "df_train_after_SFT_result,df_train_after_SFT_error = process_data(train_data[:256], data_type=\"after_train\", BATCH_SIZE=128)\n",
    "current_time2 = datetime.now()\n",
    "print(f'用时{(current_time2-current_time1).total_seconds()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d2dde-aeda-4efb-8abd-18604659ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train_after_SFT_result))\n",
    "print(len(df_train_after_SFT_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c195f24-4845-40f5-bb17-81f771b43bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_after_SFT_result,df_test_after_SFT_error = process_data(test_data, data_type=\"after_test\", BATCH_SIZE=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5008ae2-16c8-4cec-833c-9e3cb42eb941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_test_after_SFT_result))\n",
    "print(len(df_test_after_SFT_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1ffc4-8fe9-4f37-a191-549568820c38",
   "metadata": {},
   "source": [
    "## 训练后训练集测试集分类情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b982dc-751b-4971-ad7d-714dcdf98613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5ddbd-9063-49ef-b61c-0c1399efae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义评估函数\n",
    "def evaluate_model(true_labels, pred_labels):\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(true_labels, pred_labels),\n",
    "        'Precision(macro)': precision_score(true_labels, pred_labels, average='macro'),\n",
    "        'Recall(macro)': recall_score(true_labels, pred_labels, average='macro'),\n",
    "        'F1(macro)': f1_score(true_labels, pred_labels, average='macro'),\n",
    "        'Cohen Kappa': cohen_kappa_score(true_labels, pred_labels)\n",
    "    }\n",
    "    return {k: round(v, 4) for k, v in metrics.items()}\n",
    "\n",
    "# 读取数据文件\n",
    "file_map = {\n",
    "    '微调前-训练集': 'yourfile_beforeSFT_train.xlsx',\n",
    "    '微调前-测试集': 'yourfile_beforeSFT_test.xlsx',\n",
    "    '微调后-训练集': 'yourfile_afterSFT_train.xlsx',\n",
    "    '微调后-测试集': 'yourfile_afterSFT_test.xlsx'\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 处理所有数据集\n",
    "for desc, filename in file_map.items():\n",
    "    df = pd.read_excel(filename, engine='openpyxl')\n",
    "    \n",
    "    # 确保列名正确\n",
    "    if '原分类' not in df.columns or '分类' not in df.columns:\n",
    "        raise ValueError(f\"{filename} 中缺少必要的列 '原分类' 或 '分类'\")\n",
    "    \n",
    "    # 计算指标\n",
    "    metrics = evaluate_model(df['原分类'], df['分类'])\n",
    "    results[desc] = metrics\n",
    "\n",
    "# 转换为DataFrame方便比较\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# 打印完整结果\n",
    "print(\"完整评估结果：\")\n",
    "print(results_df)\n",
    "\n",
    "# 对比分析\n",
    "print(\"\\n对比分析（微调前后差异）：\")\n",
    "\n",
    "# 比较训练集\n",
    "train_diff = results_df.loc['微调后-训练集'] - results_df.loc['微调前-训练集']\n",
    "train_diff.name = '训练集差异'\n",
    "\n",
    "# 比较测试集\n",
    "test_diff = results_df.loc['微调后-测试集'] - results_df.loc['微调前-测试集']\n",
    "test_diff.name = '测试集差异'\n",
    "\n",
    "# 合并对比结果\n",
    "comparison = pd.concat([train_diff, test_diff], axis=1).T\n",
    "print(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
